2019-04-25 01:14:00,503 - INFO - allennlp.common.params - evaluate_on_test = False
2019-04-25 01:14:00,503 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'type': 'sst_tokens', 'token_indexers': {'tokens': {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'}}} and extras set()
2019-04-25 01:14:00,504 - INFO - allennlp.common.params - dataset_reader.type = sst_tokens
2019-04-25 01:14:00,504 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.stanford_sentiment_tree_bank.StanfordSentimentTreeBankDatasetReader'> from params {'token_indexers': {'tokens': {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'}}} and extras set()
2019-04-25 01:14:00,505 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'} and extras set()
2019-04-25 01:14:00,505 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = bert-pretrained
2019-04-25 01:14:00,505 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'pretrained_model': 'bert-base-uncased'} and extras set()
2019-04-25 01:14:00,506 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.pretrained_model = bert-base-uncased
2019-04-25 01:14:00,506 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.use_starting_offsets = False
2019-04-25 01:14:00,506 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.do_lowercase = True
2019-04-25 01:14:00,506 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.never_lowercase = None
2019-04-25 01:14:00,507 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_pieces = 512
2019-04-25 01:14:02,182 - INFO - pytorch_pretrained_bert.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to C:\Users\Adil\AppData\Local\Temp\tmpsq9otbs6
2019-04-25 01:14:03,263 - INFO - pytorch_pretrained_bert.file_utils - copying C:\Users\Adil\AppData\Local\Temp\tmpsq9otbs6 to cache at C:\Users\Adil\.pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-04-25 01:14:03,267 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for C:\Users\Adil\.pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-04-25 01:14:03,271 - INFO - pytorch_pretrained_bert.file_utils - removing temp file C:\Users\Adil\AppData\Local\Temp\tmpsq9otbs6
2019-04-25 01:14:03,272 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\Adil\.pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-04-25 01:14:03,303 - INFO - allennlp.common.params - dataset_reader.use_subtrees = False
2019-04-25 01:14:03,304 - INFO - allennlp.common.params - dataset_reader.granularity = 5-class
2019-04-25 01:14:03,304 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-04-25 01:14:03,304 - INFO - allennlp.common.params - validation_dataset_reader = None
2019-04-25 01:14:03,305 - INFO - allennlp.common.params - train_data_path = data/trees/train.txt
2019-04-25 01:14:03,305 - INFO - allennlp.training.util - Reading training data from data/trees/train.txt
2019-04-25 01:14:03,308 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/trees/train.txt
2019-04-25 01:14:04,756 - INFO - allennlp.common.params - validation_data_path = data/trees/dev.txt
2019-04-25 01:14:04,756 - INFO - allennlp.training.util - Reading validation data from data/trees/dev.txt
2019-04-25 01:14:04,757 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/trees/dev.txt
2019-04-25 01:14:04,924 - INFO - allennlp.common.params - test_data_path = None
2019-04-25 01:14:04,925 - INFO - allennlp.training.trainer - From dataset instances, train, validation will be considered for vocabulary creation.
2019-04-25 01:14:04,925 - INFO - allennlp.common.params - vocabulary.type = None
2019-04-25 01:14:04,925 - INFO - allennlp.common.params - vocabulary.extend = False
2019-04-25 01:14:04,925 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-04-25 01:14:04,926 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-04-25 01:14:04,926 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-04-25 01:14:04,926 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-04-25 01:14:04,927 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2019-04-25 01:14:04,927 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-04-25 01:14:04,927 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2019-04-25 01:14:04,966 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'type': 'lstm_classifier', 'word_embeddings': {'tokens': {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'}, 'allow_unmatched_keys': True}, 'encoder': {'type': 'lstm', 'input_size': 768, 'hidden_size': 128, 'batch_first': 'True'}} and extras {'vocab'}
2019-04-25 01:14:04,967 - INFO - allennlp.common.params - model.type = lstm_classifier
2019-04-25 01:14:04,967 - INFO - allennlp.common.from_params - instantiating class <class 'examples.sentiment.sst_classifier.LstmClassifier'> from params {'word_embeddings': {'tokens': {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'}, 'allow_unmatched_keys': True}, 'encoder': {'type': 'lstm', 'input_size': 768, 'hidden_size': 128, 'batch_first': 'True'}} and extras {'vocab'}
2019-04-25 01:14:04,968 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'}, 'allow_unmatched_keys': True} and extras {'vocab'}
2019-04-25 01:14:04,968 - INFO - allennlp.common.params - model.word_embeddings.type = basic
2019-04-25 01:14:04,968 - INFO - allennlp.common.params - model.word_embeddings.embedder_to_indexer_map = None
2019-04-25 01:14:04,968 - INFO - allennlp.common.params - model.word_embeddings.allow_unmatched_keys = True
2019-04-25 01:14:04,969 - INFO - allennlp.common.params - model.word_embeddings.token_embedders = None
2019-04-25 01:14:04,969 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'type': 'bert-pretrained', 'pretrained_model': 'bert-base-uncased'} and extras {'vocab'}
2019-04-25 01:14:04,969 - INFO - allennlp.common.params - model.word_embeddings.tokens.type = bert-pretrained
2019-04-25 01:14:04,969 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased'} and extras {'vocab'}
2019-04-25 01:14:04,970 - INFO - allennlp.common.params - model.word_embeddings.tokens.pretrained_model = bert-base-uncased
2019-04-25 01:14:04,970 - INFO - allennlp.common.params - model.word_embeddings.tokens.requires_grad = False
2019-04-25 01:14:04,970 - INFO - allennlp.common.params - model.word_embeddings.tokens.top_layer_only = False
2019-04-25 01:14:05,502 - INFO - pytorch_pretrained_bert.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to C:\Users\Adil\AppData\Local\Temp\tmpet_52ojg
2019-04-25 01:16:01,910 - INFO - pytorch_pretrained_bert.file_utils - copying C:\Users\Adil\AppData\Local\Temp\tmpet_52ojg to cache at C:\Users\Adil\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-04-25 01:16:02,445 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for C:\Users\Adil\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-04-25 01:16:02,449 - INFO - pytorch_pretrained_bert.file_utils - removing temp file C:\Users\Adil\AppData\Local\Temp\tmpet_52ojg
2019-04-25 01:16:02,492 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\Adil\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-04-25 01:16:02,492 - INFO - pytorch_pretrained_bert.modeling - extracting archive file C:\Users\Adil\.pytorch_pretrained_bert\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\Adil\AppData\Local\Temp\tmp1i8xhyt3
2019-04-25 01:16:06,307 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-04-25 01:16:08,150 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'type': 'lstm', 'input_size': 768, 'hidden_size': 128, 'batch_first': 'True'} and extras {'vocab'}
2019-04-25 01:16:08,151 - INFO - allennlp.common.params - model.encoder.type = lstm
2019-04-25 01:16:08,151 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 01:16:08,151 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 01:16:08,152 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 01:16:08,152 - INFO - allennlp.common.params - model.encoder.input_size = 768
2019-04-25 01:16:08,152 - INFO - allennlp.common.params - model.encoder.hidden_size = 128
2019-04-25 01:16:08,152 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 01:16:08,155 - INFO - allennlp.common.params - model.positive_label = 4
2019-04-25 01:16:08,162 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'type': 'bucket', 'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()
2019-04-25 01:16:08,163 - INFO - allennlp.common.params - iterator.type = bucket
2019-04-25 01:16:08,163 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()
2019-04-25 01:16:08,163 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]
2019-04-25 01:16:08,164 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2019-04-25 01:16:08,164 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-04-25 01:16:08,164 - INFO - allennlp.common.params - iterator.batch_size = 32
2019-04-25 01:16:08,164 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-04-25 01:16:08,165 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2019-04-25 01:16:08,165 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-04-25 01:16:08,165 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-04-25 01:16:08,165 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-04-25 01:16:08,166 - INFO - allennlp.common.params - validation_iterator = None
2019-04-25 01:16:08,166 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-04-25 01:16:08,167 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):
2019-04-25 01:16:08,167 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.word_embeddings.weight
2019-04-25 01:16:08,168 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.position_embeddings.weight
2019-04-25 01:16:08,168 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.token_type_embeddings.weight
2019-04-25 01:16:08,169 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.LayerNorm.weight
2019-04-25 01:16:08,175 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.embeddings.LayerNorm.bias
2019-04-25 01:16:08,175 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.weight
2019-04-25 01:16:08,176 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.query.bias
2019-04-25 01:16:08,176 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.weight
2019-04-25 01:16:08,176 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.key.bias
2019-04-25 01:16:08,176 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.weight
2019-04-25 01:16:08,177 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.self.value.bias
2019-04-25 01:16:08,177 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.weight
2019-04-25 01:16:08,177 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.dense.bias
2019-04-25 01:16:08,177 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-04-25 01:16:08,178 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-04-25 01:16:08,178 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.weight
2019-04-25 01:16:08,178 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.intermediate.dense.bias
2019-04-25 01:16:08,178 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.weight
2019-04-25 01:16:08,178 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.dense.bias
2019-04-25 01:16:08,179 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-04-25 01:16:08,179 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-04-25 01:16:08,179 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.weight
2019-04-25 01:16:08,179 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.query.bias
2019-04-25 01:16:08,180 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.weight
2019-04-25 01:16:08,180 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.key.bias
2019-04-25 01:16:08,180 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.weight
2019-04-25 01:16:08,180 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.self.value.bias
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.weight
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.dense.bias
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.weight
2019-04-25 01:16:08,181 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.intermediate.dense.bias
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.weight
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.dense.bias
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.weight
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.query.bias
2019-04-25 01:16:08,182 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.weight
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.key.bias
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.weight
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.self.value.bias
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.weight
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.dense.bias
2019-04-25 01:16:08,183 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.weight
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.intermediate.dense.bias
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.weight
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.dense.bias
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-04-25 01:16:08,184 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.weight
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.query.bias
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.weight
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.key.bias
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.weight
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.self.value.bias
2019-04-25 01:16:08,185 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.weight
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.dense.bias
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.weight
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.intermediate.dense.bias
2019-04-25 01:16:08,186 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.weight
2019-04-25 01:16:08,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.dense.bias
2019-04-25 01:16:08,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-04-25 01:16:08,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-04-25 01:16:08,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.weight
2019-04-25 01:16:08,187 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.query.bias
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.weight
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.key.bias
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.weight
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.self.value.bias
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.weight
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.dense.bias
2019-04-25 01:16:08,188 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.weight
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.intermediate.dense.bias
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.weight
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.dense.bias
2019-04-25 01:16:08,189 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.weight
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.query.bias
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.weight
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.key.bias
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.weight
2019-04-25 01:16:08,190 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.self.value.bias
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.weight
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.dense.bias
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.weight
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.intermediate.dense.bias
2019-04-25 01:16:08,191 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.weight
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.dense.bias
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.weight
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.query.bias
2019-04-25 01:16:08,192 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.weight
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.key.bias
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.weight
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.self.value.bias
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.weight
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.dense.bias
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-04-25 01:16:08,193 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.weight
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.intermediate.dense.bias
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.weight
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.dense.bias
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-04-25 01:16:08,194 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.weight
2019-04-25 01:16:08,195 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.query.bias
2019-04-25 01:16:08,195 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.weight
2019-04-25 01:16:08,195 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.key.bias
2019-04-25 01:16:08,195 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.weight
2019-04-25 01:16:08,195 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.self.value.bias
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.weight
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.dense.bias
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.weight
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.intermediate.dense.bias
2019-04-25 01:16:08,196 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.weight
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.dense.bias
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.weight
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.query.bias
2019-04-25 01:16:08,197 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.weight
2019-04-25 01:16:08,198 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.key.bias
2019-04-25 01:16:08,198 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.weight
2019-04-25 01:16:08,198 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.self.value.bias
2019-04-25 01:16:08,198 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.weight
2019-04-25 01:16:08,198 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.dense.bias
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.weight
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.intermediate.dense.bias
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.weight
2019-04-25 01:16:08,199 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.dense.bias
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.weight
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.query.bias
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.weight
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.key.bias
2019-04-25 01:16:08,200 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.weight
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.self.value.bias
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.weight
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.dense.bias
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.weight
2019-04-25 01:16:08,201 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.intermediate.dense.bias
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.weight
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.dense.bias
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.weight
2019-04-25 01:16:08,202 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.query.bias
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.weight
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.key.bias
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.weight
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.self.value.bias
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.weight
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.dense.bias
2019-04-25 01:16:08,203 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.weight
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.intermediate.dense.bias
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.weight
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.dense.bias
2019-04-25 01:16:08,204 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-04-25 01:16:08,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-04-25 01:16:08,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.weight
2019-04-25 01:16:08,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.query.bias
2019-04-25 01:16:08,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.weight
2019-04-25 01:16:08,205 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.key.bias
2019-04-25 01:16:08,206 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.weight
2019-04-25 01:16:08,206 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.self.value.bias
2019-04-25 01:16:08,206 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.weight
2019-04-25 01:16:08,207 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.dense.bias
2019-04-25 01:16:08,207 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-04-25 01:16:08,207 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-04-25 01:16:08,207 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.weight
2019-04-25 01:16:08,208 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.intermediate.dense.bias
2019-04-25 01:16:08,208 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.weight
2019-04-25 01:16:08,208 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.dense.bias
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.pooler.dense.weight
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens.bert_model.pooler.dense.bias
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.gamma
2019-04-25 01:16:08,209 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.0
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.1
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.2
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.3
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.4
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.5
2019-04-25 01:16:08,210 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.6
2019-04-25 01:16:08,211 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.7
2019-04-25 01:16:08,211 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.8
2019-04-25 01:16:08,211 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.9
2019-04-25 01:16:08,211 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.10
2019-04-25 01:16:08,220 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_tokens._scalar_mix.scalar_parameters.11
2019-04-25 01:16:08,221 - INFO - allennlp.training.trainer - encoder._module.weight_ih_l0
2019-04-25 01:16:08,221 - INFO - allennlp.training.trainer - encoder._module.weight_hh_l0
2019-04-25 01:16:08,221 - INFO - allennlp.training.trainer - encoder._module.bias_ih_l0
2019-04-25 01:16:08,222 - INFO - allennlp.training.trainer - encoder._module.bias_hh_l0
2019-04-25 01:16:08,222 - INFO - allennlp.training.trainer - linear.weight
2019-04-25 01:16:08,222 - INFO - allennlp.training.trainer - linear.bias
2019-04-25 01:16:08,223 - INFO - allennlp.common.params - trainer.patience = 5
2019-04-25 01:16:08,223 - INFO - allennlp.common.params - trainer.validation_metric = -loss
2019-04-25 01:16:08,223 - INFO - allennlp.common.params - trainer.shuffle = True
2019-04-25 01:16:08,223 - INFO - allennlp.common.params - trainer.num_epochs = 20
2019-04-25 01:16:08,223 - INFO - allennlp.common.params - trainer.cuda_device = -1
2019-04-25 01:16:08,224 - INFO - allennlp.common.params - trainer.grad_norm = None
2019-04-25 01:16:08,224 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-04-25 01:16:08,224 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-04-25 01:16:08,224 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-04-25 01:16:08,225 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2019-04-25 01:16:08,225 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2019-04-25 01:16:08,225 - INFO - allennlp.training.optimizers - Number of trainable parameters: 460434
2019-04-25 01:16:08,226 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True
2019-04-25 01:16:08,226 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 01:16:08,226 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 01:16:08,226 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-04-25 01:16:08,227 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-04-25 01:16:08,231 - INFO - allennlp.training.trainer - Beginning training.
2019-04-25 01:16:08,232 - INFO - allennlp.training.trainer - Epoch 0/19
2019-04-25 01:16:08,232 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 01:16:08,237 - INFO - allennlp.training.trainer - Training
2019-04-25 01:25:52,848 - INFO - allennlp.training.trainer - Validating
2019-04-25 01:26:59,197 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 01:26:59,198 - INFO - allennlp.training.tensorboard_writer - precision     |     0.431  |     0.500
2019-04-25 01:26:59,199 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 01:26:59,200 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.213  |     0.137
2019-04-25 01:26:59,202 - INFO - allennlp.training.tensorboard_writer - loss          |     1.339  |     1.233
2019-04-25 01:26:59,214 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.408  |     0.456
2019-04-25 01:26:59,214 - INFO - allennlp.training.tensorboard_writer - recall        |     0.142  |     0.079
2019-04-25 01:26:59,616 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'sst-model_bert/best.th'.
2019-04-25 01:27:00,476 - INFO - allennlp.training.trainer - Epoch duration: 00:10:52
2019-04-25 01:27:00,476 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:26:32
2019-04-25 01:27:00,476 - INFO - allennlp.training.trainer - Epoch 1/19
2019-04-25 01:27:00,477 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 01:27:00,483 - INFO - allennlp.training.trainer - Training
2019-04-25 01:36:48,255 - INFO - allennlp.training.trainer - Validating
2019-04-25 01:37:53,179 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 01:37:53,179 - INFO - allennlp.training.tensorboard_writer - precision     |     0.562  |     0.505
2019-04-25 01:37:53,180 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 01:37:53,180 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.417  |     0.400
2019-04-25 01:37:53,181 - INFO - allennlp.training.tensorboard_writer - loss          |     1.146  |     1.214
2019-04-25 01:37:53,181 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.510  |     0.454
2019-04-25 01:37:53,183 - INFO - allennlp.training.tensorboard_writer - recall        |     0.332  |     0.331
2019-04-25 01:37:53,610 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'sst-model_bert/best.th'.
2019-04-25 01:37:54,201 - INFO - allennlp.training.trainer - Epoch duration: 00:10:53
2019-04-25 01:37:54,202 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:15:53
2019-04-25 01:37:54,202 - INFO - allennlp.training.trainer - Epoch 2/19
2019-04-25 01:37:54,202 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 01:37:54,207 - INFO - allennlp.training.trainer - Training
2019-04-25 01:47:39,593 - INFO - allennlp.training.trainer - Validating
2019-04-25 01:48:44,804 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 01:48:44,805 - INFO - allennlp.training.tensorboard_writer - precision     |     0.627  |     0.392
2019-04-25 01:48:44,805 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 01:48:44,806 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.549  |     0.456
2019-04-25 01:48:44,807 - INFO - allennlp.training.tensorboard_writer - loss          |     0.980  |     1.296
2019-04-25 01:48:44,807 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.591  |     0.420
2019-04-25 01:48:44,808 - INFO - allennlp.training.tensorboard_writer - recall        |     0.488  |     0.547
2019-04-25 01:48:45,132 - INFO - allennlp.training.trainer - Epoch duration: 00:10:50
2019-04-25 01:48:45,133 - INFO - allennlp.training.trainer - Estimated training time remaining: 3:04:49
2019-04-25 01:48:45,141 - INFO - allennlp.training.trainer - Epoch 3/19
2019-04-25 01:48:45,141 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 01:48:45,147 - INFO - allennlp.training.trainer - Training
2019-04-25 01:58:31,561 - INFO - allennlp.training.trainer - Validating
2019-04-25 01:59:36,170 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 01:59:36,171 - INFO - allennlp.training.tensorboard_writer - precision     |     0.752  |     0.418
2019-04-25 01:59:36,171 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 01:59:36,172 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.709  |     0.369
2019-04-25 01:59:36,172 - INFO - allennlp.training.tensorboard_writer - loss          |     0.735  |     1.356
2019-04-25 01:59:36,173 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.719  |     0.451
2019-04-25 01:59:36,173 - INFO - allennlp.training.tensorboard_writer - recall        |     0.670  |     0.331
2019-04-25 01:59:36,565 - INFO - allennlp.training.trainer - Epoch duration: 00:10:51
2019-04-25 01:59:36,565 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:53:53
2019-04-25 01:59:36,566 - INFO - allennlp.training.trainer - Epoch 4/19
2019-04-25 01:59:36,566 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 01:59:36,571 - INFO - allennlp.training.trainer - Training
2019-04-25 02:09:26,408 - INFO - allennlp.training.trainer - Validating
2019-04-25 02:10:31,966 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 02:10:31,974 - INFO - allennlp.training.tensorboard_writer - precision     |     0.881  |     0.445
2019-04-25 02:10:31,975 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 02:10:31,975 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.854  |     0.411
2019-04-25 02:10:31,975 - INFO - allennlp.training.tensorboard_writer - loss          |     0.476  |     1.487
2019-04-25 02:10:31,976 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.843  |     0.457
2019-04-25 02:10:31,977 - INFO - allennlp.training.tensorboard_writer - recall        |     0.829  |     0.381
2019-04-25 02:10:32,452 - INFO - allennlp.training.trainer - Epoch duration: 00:10:55
2019-04-25 02:10:32,452 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:43:12
2019-04-25 02:10:32,452 - INFO - allennlp.training.trainer - Epoch 5/19
2019-04-25 02:10:32,453 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 02:10:32,458 - INFO - allennlp.training.trainer - Training
2019-04-25 02:20:07,323 - INFO - allennlp.training.trainer - Validating
2019-04-25 02:21:09,149 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-25 02:21:09,150 - INFO - allennlp.training.tensorboard_writer - precision     |     0.944  |     0.389
2019-04-25 02:21:09,151 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |     0.000  |       N/A
2019-04-25 02:21:09,163 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.937  |     0.370
2019-04-25 02:21:09,164 - INFO - allennlp.training.tensorboard_writer - loss          |     0.270  |     1.660
2019-04-25 02:21:09,164 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.930  |     0.441
2019-04-25 02:21:09,165 - INFO - allennlp.training.tensorboard_writer - recall        |     0.930  |     0.353
2019-04-25 02:21:09,581 - INFO - allennlp.training.trainer - Epoch duration: 00:10:37
2019-04-25 02:21:09,581 - INFO - allennlp.training.trainer - Estimated training time remaining: 2:31:43
2019-04-25 02:21:09,581 - INFO - allennlp.training.trainer - Epoch 6/19
2019-04-25 02:21:09,582 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 0.0
2019-04-25 02:21:09,587 - INFO - allennlp.training.trainer - Training
2019-04-25 02:30:34,720 - INFO - allennlp.training.trainer - Validating
2019-04-25 02:31:36,514 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2019-04-25 02:31:36,515 - INFO - allennlp.training.checkpointer - loading best weights
